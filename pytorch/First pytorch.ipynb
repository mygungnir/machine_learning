{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-283378e61b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V_data = [1., 2., 3.]\n",
    "V = torch.Tensor(V_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1\n",
      " 2\n",
      " 3\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = [ (\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "         (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "         (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "         (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\") ,\n",
    "         (\"今日 は 結構 大変 だった\", \"JAPANESE\"),  \n",
    "         (\"世の中 うまく いかない ものだ ハンバーグ が 食べたい\", \"JAPANESE\")\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = [ (\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "              (\"it is lost on me\".split(), \"ENGLISH\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_data' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-00234e7d8d72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_data' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c031d3dd82fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず、自動微分から"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.ones(2,2), requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n 1  1\n 1  1\n[torch.FloatTensor of size 2x2]\n\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x +5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n 6  6\n 6  6\n[torch.FloatTensor of size 2x2]\n\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x7f46b8833cc0>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylor_sine(x):   # サイン関数のテイラー近似（マクローリン展開）\n",
    "    ans = currterm = x\n",
    "    i = 0\n",
    "    while np.abs(currterm) > 0.001:\n",
    "        currterm = -currterm * x**2 / ((2 * i + 3) * (2 * i + 2))\n",
    "        ans = ans + currterm\n",
    "        i += 1\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kota/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:279: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3db673f56c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "xs = np.arange(0, 2 * np.pi, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np # Numpy用の薄いラッパ\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(0, 2 * np.pi, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.01  0.02  0.03  0.04  0.05  0.06  0.07  0.08  0.09  0.1   0.11\n  0.12  0.13  0.14  0.15  0.16  0.17  0.18  0.19  0.2   0.21  0.22  0.23\n  0.24  0.25  0.26  0.27  0.28  0.29  0.3   0.31  0.32  0.33  0.34  0.35\n  0.36  0.37  0.38  0.39  0.4   0.41  0.42  0.43  0.44  0.45  0.46  0.47\n  0.48  0.49  0.5   0.51  0.52  0.53  0.54  0.55  0.56  0.57  0.58  0.59\n  0.6   0.61  0.62  0.63  0.64  0.65  0.66  0.67  0.68  0.69  0.7   0.71\n  0.72  0.73  0.74  0.75  0.76  0.77  0.78  0.79  0.8   0.81  0.82  0.83\n  0.84  0.85  0.86  0.87  0.88  0.89  0.9   0.91  0.92  0.93  0.94  0.95\n  0.96  0.97  0.98  0.99  1.    1.01  1.02  1.03  1.04  1.05  1.06  1.07\n  1.08  1.09  1.1   1.11  1.12  1.13  1.14  1.15  1.16  1.17  1.18  1.19\n  1.2   1.21  1.22  1.23  1.24  1.25  1.26  1.27  1.28  1.29  1.3   1.31\n  1.32  1.33  1.34  1.35  1.36  1.37  1.38  1.39  1.4   1.41  1.42  1.43\n  1.44  1.45  1.46  1.47  1.48  1.49  1.5   1.51  1.52  1.53  1.54  1.55\n  1.56  1.57  1.58  1.59  1.6   1.61  1.62  1.63  1.64  1.65  1.66  1.67\n  1.68  1.69  1.7   1.71  1.72  1.73  1.74  1.75  1.76  1.77  1.78  1.79\n  1.8   1.81  1.82  1.83  1.84  1.85  1.86  1.87  1.88  1.89  1.9   1.91\n  1.92  1.93  1.94  1.95  1.96  1.97  1.98  1.99  2.    2.01  2.02  2.03\n  2.04  2.05  2.06  2.07  2.08  2.09  2.1   2.11  2.12  2.13  2.14  2.15\n  2.16  2.17  2.18  2.19  2.2   2.21  2.22  2.23  2.24  2.25  2.26  2.27\n  2.28  2.29  2.3   2.31  2.32  2.33  2.34  2.35  2.36  2.37  2.38  2.39\n  2.4   2.41  2.42  2.43  2.44  2.45  2.46  2.47  2.48  2.49  2.5   2.51\n  2.52  2.53  2.54  2.55  2.56  2.57  2.58  2.59  2.6   2.61  2.62  2.63\n  2.64  2.65  2.66  2.67  2.68  2.69  2.7   2.71  2.72  2.73  2.74  2.75\n  2.76  2.77  2.78  2.79  2.8   2.81  2.82  2.83  2.84  2.85  2.86  2.87\n  2.88  2.89  2.9   2.91  2.92  2.93  2.94  2.95  2.96  2.97  2.98  2.99\n  3.    3.01  3.02  3.03  3.04  3.05  3.06  3.07  3.08  3.09  3.1   3.11\n  3.12  3.13  3.14  3.15  3.16  3.17  3.18  3.19  3.2   3.21  3.22  3.23\n  3.24  3.25  3.26  3.27  3.28  3.29  3.3   3.31  3.32  3.33  3.34  3.35\n  3.36  3.37  3.38  3.39  3.4   3.41  3.42  3.43  3.44  3.45  3.46  3.47\n  3.48  3.49  3.5   3.51  3.52  3.53  3.54  3.55  3.56  3.57  3.58  3.59\n  3.6   3.61  3.62  3.63  3.64  3.65  3.66  3.67  3.68  3.69  3.7   3.71\n  3.72  3.73  3.74  3.75  3.76  3.77  3.78  3.79  3.8   3.81  3.82  3.83\n  3.84  3.85  3.86  3.87  3.88  3.89  3.9   3.91  3.92  3.93  3.94  3.95\n  3.96  3.97  3.98  3.99  4.    4.01  4.02  4.03  4.04  4.05  4.06  4.07\n  4.08  4.09  4.1   4.11  4.12  4.13  4.14  4.15  4.16  4.17  4.18  4.19\n  4.2   4.21  4.22  4.23  4.24  4.25  4.26  4.27  4.28  4.29  4.3   4.31\n  4.32  4.33  4.34  4.35  4.36  4.37  4.38  4.39  4.4   4.41  4.42  4.43\n  4.44  4.45  4.46  4.47  4.48  4.49  4.5   4.51  4.52  4.53  4.54  4.55\n  4.56  4.57  4.58  4.59  4.6   4.61  4.62  4.63  4.64  4.65  4.66  4.67\n  4.68  4.69  4.7   4.71  4.72  4.73  4.74  4.75  4.76  4.77  4.78  4.79\n  4.8   4.81  4.82  4.83  4.84  4.85  4.86  4.87  4.88  4.89  4.9   4.91\n  4.92  4.93  4.94  4.95  4.96  4.97  4.98  4.99  5.    5.01  5.02  5.03\n  5.04  5.05  5.06  5.07  5.08  5.09  5.1   5.11  5.12  5.13  5.14  5.15\n  5.16  5.17  5.18  5.19  5.2   5.21  5.22  5.23  5.24  5.25  5.26  5.27\n  5.28  5.29  5.3   5.31  5.32  5.33  5.34  5.35  5.36  5.37  5.38  5.39\n  5.4   5.41  5.42  5.43  5.44  5.45  5.46  5.47  5.48  5.49  5.5   5.51\n  5.52  5.53  5.54  5.55  5.56  5.57  5.58  5.59  5.6   5.61  5.62  5.63\n  5.64  5.65  5.66  5.67  5.68  5.69  5.7   5.71  5.72  5.73  5.74  5.75\n  5.76  5.77  5.78  5.79  5.8   5.81  5.82  5.83  5.84  5.85  5.86  5.87\n  5.88  5.89  5.9   5.91  5.92  5.93  5.94  5.95  5.96  5.97  5.98  5.99\n  6.    6.01  6.02  6.03  6.04  6.05  6.06  6.07  6.08  6.09  6.1   6.11\n  6.12  6.13  6.14  6.15  6.16  6.17  6.18  6.19  6.2   6.21  6.22  6.23\n  6.24  6.25  6.26  6.27  6.28]\n"
     ]
    }
   ],
   "source": [
    "print(xs\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "print(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
